{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3baef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "\n",
    "# if you have less than 10 columns, just include \"Extra Columns\" for the unused ones otherwise you will break the SQL.\n",
    "# any column before ColumnUPC doesn't really matter\n",
    "# remember that these columns must match what's in the workbook exactly\n",
    "Column1 = 'ASIN'\n",
    "Column2 = 'VendorCode'\n",
    "ColumnUPC = 'UPC'\n",
    "Column4 = 'April'\n",
    "Column5 = 'May'\n",
    "Column6 = 'June'\n",
    "Column7 = 'July'\n",
    "Column8 = 'August'\n",
    "Column9 = 'September'\n",
    "Column10 = 'October'\n",
    "\n",
    "\n",
    "dataset = pd.read_excel(r'P70 Forecast_KEECS.xlsx', sheet_name='Monthly forecast')\n",
    "df = pd.DataFrame(dataset)\n",
    "# The column number must be accurate otherwise it will result in an error\n",
    "cols = [1,2,3,4,5,6,7,8,9,10]\n",
    "upc = df[df.columns[cols]]\n",
    "# Remember you need to be on the VPN for this to work\n",
    "conn = pyodbc.connect('Driver={Sql Server};'\n",
    "                      'Server=PDX-SQL-03;'\n",
    "                      'Database=KEEN_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "temp_creator = '''CREATE TABLE #P70_UPC ('''+str(ColumnUPC)+''' bigint, ''' +str(Column4)+'''  \n",
    "int, ''' +str(Column5)+'''  int, ''' +str(Column6)+'''  int, ''' +str(Column7)+'''  \n",
    "int, ''' +str(Column8)+'''  int, ''' +str(Column9)+'''  int, ''' +str(Column10)+'''  int);''' \n",
    "cursor.execute(temp_creator)\n",
    "df_insert = upc\n",
    "df_json = df_insert.to_json(orient='records', double_precision=0)\n",
    "\n",
    "load_df = '''\n",
    " insert into #P70_UPC('''+str(ColumnUPC)+''', '''+str(Column4)+''', '''+str(Column5)+''', '''+str(Column6)+'''\n",
    " , '''+str(Column7)+''', '''+str(Column8)+''', '''+str(Column9)+''', '''+str(Column10)+''')\n",
    " select '''+str(ColumnUPC)+''', '''+str(Column4)+''', '''+str(Column5)+''', '''+str(Column6)+'''\n",
    " , '''+str(Column7)+''', '''+str(Column8)+''', '''+str(Column9)+''', '''+str(Column10)+'''\n",
    " from openjson(?)\n",
    " with \n",
    " (\n",
    "   '''+str(ColumnUPC)+''' bigint '$.'''+str(ColumnUPC)+'''',\n",
    "   '''+str(Column4)+''' int '$.'''+str(Column4)+'''',\n",
    "   '''+str(Column5)+''' int '$.'''+str(Column5)+'''',\n",
    "   '''+str(Column6)+''' int '$.'''+str(Column6)+'''',\n",
    "   '''+str(Column7)+''' int '$.'''+str(Column7)+'''',\n",
    "   '''+str(Column8)+''' int '$.'''+str(Column8)+'''',\n",
    "   '''+str(Column9)+''' int '$.'''+str(Column9)+'''',\n",
    "   '''+str(Column10)+''' int '$.'''+str(Column10)+''''\n",
    " );\n",
    " '''\n",
    "cursor.execute(load_df,df_json)\n",
    "read_query = '''SELECT * FROM #P70_UPC'''\n",
    "df_back = pd.read_sql(read_query,conn)\n",
    "read_query = '''WITH [Aggregate] AS (\n",
    "                SELECT DISTINCT M.Material\n",
    "                , M.MaterialDescription\n",
    "                ,CASE WHEN M.Material IN \n",
    "                    (SELECT SAPMaterialNo FROM vwCentricLineList WHERE Season = 'Fall 2022' ) \n",
    "                    THEN 'INLINE'ELSE 'DISCO' END AS Inline_Stat\n",
    "                    , P.'''+str(ColumnUPC)+'''\n",
    "                    , '''+str(Column4)+'''\n",
    "                    , '''+str(Column5)+'''\n",
    "                    , '''+str(Column6)+'''\n",
    "                    , '''+str(Column7)+'''\n",
    "                    , '''+str(Column8)+'''\n",
    "                    , '''+str(Column9)+'''\n",
    "                    , '''+str(Column10)+'''\n",
    "                    FROM vwUPC U\n",
    "                INNER JOIN #P70_UPC P\n",
    "                ON U.UPC = P.'''+str(ColumnUPC)+'''\n",
    "                INNER JOIN vwKA_Material M\n",
    "                ON U.Material = M. Material )\n",
    "                \n",
    "                SELECT \n",
    "                CAST(Material as int) AS Material\n",
    "                , MaterialDescription\n",
    "                , Inline_Stat\n",
    "                , SUM('''+str(Column4)+''') AS '''+str(Column4)+'''\n",
    "                , SUM('''+str(Column5)+''') AS '''+str(Column5)+'''\n",
    "                , SUM('''+str(Column6)+''') AS '''+str(Column6)+'''\n",
    "                , SUM('''+str(Column7)+''') AS '''+str(Column7)+'''\n",
    "                , SUM('''+str(Column8)+''') AS '''+str(Column8)+'''\n",
    "                , SUM('''+str(Column9)+''') AS '''+str(Column9)+'''\n",
    "                , SUM('''+str(Column10)+''') AS '''+str(Column10)+'''\n",
    "                FROM [Aggregate] A\n",
    "               \n",
    "                GROUP BY Material, MaterialDescription, Inline_Stat\n",
    "                \n",
    "                ORDER BY '''+str(Column4)+''' DESC\n",
    "               '''\n",
    "\n",
    "df_back = pd.read_sql(read_query,conn)\n",
    "\n",
    "df_back.to_excel(r'P70_Output.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ac569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1a7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
